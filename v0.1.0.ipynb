{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3cc840f-cbaa-472d-85ed-0054567f01e5",
   "metadata": {},
   "source": [
    "# Contagem de veículos (v0.1.0)\n",
    "Para a câmera dos primeiros 23 minutos - https://www.youtube.com/watch?v=3uwRHtiyMnI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a2adaa3-0137-47dd-aabd-45faf84f2dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "\n",
    "import cv2\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d8c3932-f833-482c-a2f6-9d530eb9afac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea384675-6ef3-438a-bf85-8807c169135c",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = 'camera.mp4'  # Local video path or RSTP Url\n",
    "limit_count_not_detected = 30  # How many frames without detect a track id until remove from history\n",
    "debug = True  # Whether to save predictions images\n",
    "\n",
    "if debug:\n",
    "    Path('debug').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# If model was already executed, reset tracker id\n",
    "if model.predictor:\n",
    "    model.predictor.trackers[0].reset_id()\n",
    "\n",
    "counter = {'left': 0, 'right': 0}\n",
    "detections = {}\n",
    "idx_frame = 0\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    raise ConnectionError('Not possible to load image')\n",
    "\n",
    "is_rtsp = video_path.startswith('rtsp://')\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        if is_rtsp:\n",
    "            print('Failed to receive image from RTSP stream')\n",
    "            continue\n",
    "        else:\n",
    "            print('Video processed successfully!')\n",
    "            break\n",
    "        \n",
    "    results_video = model.track(source=frame,  # image or video; single value or a list; URL, PIL (RGB), CV2 (BGR), ...\n",
    "                                conf=0.25,\n",
    "                                iou=0.7,\n",
    "                                imgsz=640,\n",
    "                                classes=[2, 3, 5, 7],\n",
    "                                show=False,\n",
    "                                save=False,\n",
    "                                save_txt=False,  # Save bbox coordination\n",
    "                                save_conf=False,  # save_txt must be True\n",
    "                                save_crop=False,\n",
    "                                verbose=False,\n",
    "                                persist=True,  # To continue tracker_id\n",
    "                               )\n",
    "\n",
    "    if debug:\n",
    "        img = deepcopy(frame)\n",
    "        cv2.line(img, (649, 590), (180, 590), (0, 0, 255), 3)  # Left\n",
    "        cv2.line(img, (650, 531), (1023, 531), (255, 0, 0), 3)  # Right\n",
    "        cv2.line(img, (650, 1280), (650, 0), (255, 0, 255), 3)  # Division\n",
    "    \n",
    "    for result in results_video:\n",
    "        for idx in range(len(result.boxes.cls)):\n",
    "            track_id = int(result.boxes.id[idx])\n",
    "            \n",
    "            center_x = int((result.boxes.xyxy[idx][0] + result.boxes.xyxy[idx][2]) / 2)\n",
    "            center_y = int((result.boxes.xyxy[idx][1] + result.boxes.xyxy[idx][3]) / 2)\n",
    "    \n",
    "            side = 'left' if center_x < 650 else 'right'\n",
    "            if side == 'left':\n",
    "                position_y = 'up' if center_y < 590 else 'down'\n",
    "            else:\n",
    "                position_y = 'up' if center_y < 531 else 'down'\n",
    "    \n",
    "            if debug:\n",
    "                circle_color = (0, 0, 200) if side == 'left' else (200, 0, 0)\n",
    "                cv2.circle(img, (center_x, center_y), color=circle_color, radius=1, thickness=10)\n",
    "                cv2.putText(img, f'{track_id}-{int(result.boxes.cls[idx])}', (center_x, center_y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "            \n",
    "            # Track_id already detected\n",
    "            if track_id in detections:\n",
    "                detections[track_id]['count_not_detected'] = 0\n",
    "                if detections[track_id]['position_y'] != position_y:\n",
    "                    # Only consider those who crossed the line at the correct position_y, otherwise, treat it as a mistake and ignore it\n",
    "                    if (side == 'left' and position_y == 'down') or (side == 'right' and position_y == 'up'):\n",
    "                        counter[side] += 1\n",
    "                        detections[track_id]['position_y'] = position_y\n",
    "            # New track_id\n",
    "            else:\n",
    "                detections[track_id] = {'count_not_detected': 0, 'side': side, 'position_y': position_y}\n",
    "    \n",
    "    if debug:\n",
    "        # White board\n",
    "        cv2.rectangle(img, (10, 10), (230, 95), (255, 255, 255), thickness=-1)\n",
    "        cv2.rectangle(img, (10, 10), (230, 95), (0, 0, 0), thickness=2)\n",
    "        cv2.putText(img, f'Left: {counter['left']}', (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "        cv2.putText(img, f'Right: {counter['right']}', (20, 80), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "        cv2.imwrite(f'debug/{idx_frame}.png', img)\n",
    "        idx_frame += 1\n",
    "    \n",
    "    # Remove any detections that no longer exist for N consecutive frames\n",
    "    for key in list(detections.keys()):\n",
    "        detections[key]['count_not_detected'] += 1\n",
    "        if detections[key]['count_not_detected'] >= limit_count_not_detected:\n",
    "            del detections[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e827c47c-acc5-4ad6-8cf5-d1486d1ebe6e",
   "metadata": {},
   "source": [
    "### Converte debug imagens para vídeo\n",
    "Não faz parte do sistema principal, utilizado apenas para facilitar no debug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3640f02a-31ab-45c1-85d0-d720705b8475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved as: output_video.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Path to the folder containing images\n",
    "image_folder = 'debug'\n",
    "pattern = os.path.join(image_folder, '*.png')\n",
    "\n",
    "# Get list of image file paths matching the pattern\n",
    "image_paths = glob.glob(pattern)\n",
    "\n",
    "# Sort image paths based on the numeric value of the filename (e.g., 0.png, 1.png, 3.png)\n",
    "def get_index_from_filename(path):\n",
    "    filename = os.path.basename(path)         # e.g., '3.png'\n",
    "    index_str = os.path.splitext(filename)[0] # e.g., '3'\n",
    "    return int(index_str)                     # Convert to integer\n",
    "\n",
    "# Sort using the extracted index\n",
    "image_paths = sorted(image_paths, key=get_index_from_filename)\n",
    "\n",
    "# Check if there are any images to process\n",
    "if not image_paths:\n",
    "    print(\"No images found.\")\n",
    "    exit()\n",
    "\n",
    "# Read the first image to get dimensions\n",
    "sample_img = cv2.imread(image_paths[0])\n",
    "height, width, _ = sample_img.shape\n",
    "\n",
    "# Video output settings\n",
    "output_video_path = 'output_video.mp4'\n",
    "fps = 30\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "video_writer = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "# Write each image to the video\n",
    "for img_path in image_paths:\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(f\"Failed to load image: {img_path}\")\n",
    "        continue\n",
    "    video_writer.write(img)\n",
    "\n",
    "# Release the video writer and finish\n",
    "video_writer.release()\n",
    "print(f\"Video saved as: {output_video_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
